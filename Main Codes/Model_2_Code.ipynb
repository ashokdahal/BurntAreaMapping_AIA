{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model 2 Code",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPr/HFpBVXKGj0sChHxcEmv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashokdahal/BurntAreaMapping_AIA/blob/main/Model_2_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n2ZH7lxdc2r"
      },
      "source": [
        "<h1> Burnt Area Mapping using FCNN (Model 2) and the Sentinel 2 Images using FCN-DK2</h1>\n",
        "Code Author: Ashok Dahal \n",
        "\n",
        "\n",
        "***This code is developed for the assignment of the Advanced Image Analysis Course, and hence, has not been peer reviewd and verfied, use at your own risk***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWyyFIrvrwXd"
      },
      "source": [
        "# Load libraries and prepare connect to data folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LedIJU2zdX5-"
      },
      "source": [
        "#connect to the goolge drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QmzBZgmeTNI"
      },
      "source": [
        "#Import the required Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import gdal\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "pylab.rcParams['figure.figsize'] = (15, 10)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from skimage import exposure\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Activation, BatchNormalization, Reshape\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD, Adadelta\n",
        "\n",
        "import tensorflow.python.keras.backend as K\n",
        "sess = K.get_session()\n",
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "from keras.layers import LeakyReLU\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt \n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FBEE2XVeY89"
      },
      "source": [
        "#Define File directories\n",
        "Data_folder = \"Directory for the folder\"\n",
        "IMAGE_PATH = os.path.join(Data_folder, \"ImageNBR\") #Load either ImageNBR or Image depending on which data you are training \n",
        "LABEL_PATH = os.path.join(Data_folder, \"Label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hewRYLyMgYL5"
      },
      "source": [
        "#Load and Prepare the required dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_-7pGp4eu-m"
      },
      "source": [
        "#Create list of sentinel images \n",
        "image_list={}\n",
        "for f in sorted(os.listdir(IMAGE_PATH)):\n",
        "    fdir = os.path.join(IMAGE_PATH, f)\n",
        "    _, ext = os.path.splitext(f)\n",
        "    if ext.lower() == \".tif\":\n",
        "        imgtype = f[-9:-4]\n",
        "        image_data=gdal.Open(fdir)\n",
        "        bands = [image_data.GetRasterBand(image_data.RasterCount).ReadAsArray()]\n",
        "        image_list[imgtype] = np.stack(bands, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xvhlXE7gfOy"
      },
      "source": [
        "#Create list of Lables\n",
        "label_list={}\n",
        "for f in sorted(os.listdir(LABEL_PATH)):\n",
        "    fdir = os.path.join(LABEL_PATH, f)\n",
        "    _, ext = os.path.splitext(f)\n",
        "    if ext.lower() == \".tif\":\n",
        "        imgtype = f[-9:-4]\n",
        "        label_data=gdal.Open(fdir)\n",
        "        bands = [label_data.GetRasterBand(label_data.RasterCount).ReadAsArray()]\n",
        "        label_list[imgtype] = np.stack(bands, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XLwDlKg1EV"
      },
      "source": [
        "#visualize both images \n",
        "sample_image=\"00004\"\n",
        "sample_label=\"00004\"\n",
        "\n",
        "def visualize_data(data,data2):\n",
        "    f, axarr = plt.subplots(1,2)\n",
        "    data = data[:, :, 0:3]\n",
        "    _ = data[:, :, 0].copy()\n",
        "    data[:, :, 0] = data[:, :, 2]\n",
        "    data[:, :, 2] = _\n",
        "    data = data.astype(np.float)\n",
        "    for i in range(data.shape[2]):\n",
        "        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n",
        "        data[:, :, i] = exposure.rescale_intensity(data[:, :, i],\n",
        "                                                      in_range=(p2, p98))\n",
        "    axarr[0].imshow(data)\n",
        "    axarr[0].set_title(\"Satellite image\")\n",
        "\n",
        "    a=axarr[1]\n",
        "    values = np.unique(data2.ravel())\n",
        "    im = axarr[1].imshow(data2[:,:,0])\n",
        "    a.set_title(\"Labeled image\")\n",
        "    colors = [im.cmap(im.norm(value)) for value in values] \n",
        "    data2 = [\"Not Burnt Area\", \"Burnt Area\"]\n",
        "    patches = [mpatches.Patch(color=colors[i], label=j) for i, j in zip(range(len(values)), data2)]\n",
        "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
        "\n",
        "visualize_data(image_list[sample_image],label_list[sample_label]) #Visualize Images Side by Side\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8BnWfKelkV"
      },
      "source": [
        "#convert data into smaller patches and keras usable formats\n",
        "\n",
        "PATCHSIZE = 128\n",
        "NBANDS = image_list[\"00001\"].shape[-1]\n",
        "\n",
        "def gridwise_sample(imgarray, patchsize):\n",
        "    \"\"\"Extract sample patches of size patchsize x patchsize from an image (imgarray) in a gridwise manner.\n",
        "    \"\"\"\n",
        "    nrows, ncols, nbands = imgarray.shape\n",
        "    patchsamples = np.zeros(shape=(0, patchsize, patchsize, nbands),\n",
        "                            dtype=imgarray.dtype)\n",
        "    for i in range(int(nrows/patchsize)):\n",
        "        for j in range(int(ncols/patchsize)):\n",
        "            tocat = imgarray[i*patchsize:(i+1)*patchsize,\n",
        "                             j*patchsize:(j+1)*patchsize, :]\n",
        "            tocat = np.expand_dims(tocat, axis=0)\n",
        "            patchsamples = np.concatenate((patchsamples, tocat),\n",
        "                                          axis=0)\n",
        "    return patchsamples\n",
        "\n",
        "Xtrain = np.zeros(shape=(0, PATCHSIZE, PATCHSIZE, NBANDS), dtype=np.float32)\n",
        "Ytrain = np.zeros(shape=(0, PATCHSIZE, PATCHSIZE, 1), dtype=np.uint8)\n",
        "# sample each training tile systematically in a gridwise manner\n",
        "train_areas = [\"00000\", \"00002\", \"00003\",\"00004\",\"00005\",\"00010\",\"00012\",\"00013\"] #00001 and 00011 are used as test\n",
        "for area in train_areas:\n",
        "    X_toadd = gridwise_sample(image_list[area], PATCHSIZE)\n",
        "    Y_toadd = gridwise_sample(label_list[area], PATCHSIZE)\n",
        "    Xtrain = np.concatenate((Xtrain, X_toadd), axis=0)\n",
        "    Ytrain = np.concatenate((Ytrain, Y_toadd), axis=0)\n",
        "# encode all non-informal settlement classes as one class\n",
        "Ytrain[Ytrain!=2] = 1\n",
        "print(\"There are %i number of training patches\" % (Xtrain.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc1id9NtsVxI"
      },
      "source": [
        "nb_px=len(Ytrain[Ytrain==1])/(len(Ytrain[Ytrain==1])+len(Ytrain[Ytrain==2]))\n",
        "yb_px=len(Ytrain[Ytrain==2])/(len(Ytrain[Ytrain==1])+len(Ytrain[Ytrain==2]))\n",
        "print(\"there are %f percent pixels of burnt pixels and %f percent pixels of not burnt pixels\" % (yb_px*100,nb_px*100) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlmLZp8wr7Hp"
      },
      "source": [
        "#Visualize the Patches of Image\n",
        "PATCH_NO = 490\n",
        "visualize_data(Xtrain[PATCH_NO],Ytrain[PATCH_NO])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY8npoUYvHl3"
      },
      "source": [
        "Convert Label data to categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUNMZ3ewulKG"
      },
      "source": [
        "def to_categorical_4d(y, nc):\n",
        "    Y = np.zeros((y.shape[0],\n",
        "                  y.shape[1],\n",
        "                  y.shape[2],\n",
        "                  nc),\n",
        "                  dtype=np.int32)\n",
        "    for h in range(y.shape[0]):\n",
        "        for i in range(y.shape[1]):\n",
        "            for j in range(y.shape[2]):\n",
        "                if y[h, i, j, 0] != 0:\n",
        "                    Y[h, i, j, y[h, i, j, 0]-1] = 1\n",
        "                else:\n",
        "                    continue\n",
        "    return Y\n",
        "# transform target arrays to one-hot encodings\n",
        "Ytrain = to_categorical_4d(Ytrain, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vp3QXVzrcwt"
      },
      "source": [
        "# Create a FCNN model and train it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA6d1u0ZrjI6"
      },
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
        "set_session(tf.compat.v1.Session(config=config))\n",
        "\n",
        "NUMBER_BANDS = 1\n",
        "NUMBER_CLASSES = 2\n",
        "NUMBER_EPOCHS = 150 \n",
        "nclasses=2\n",
        "def build_FCN(optimizer, nrows, ncols, nbands,nclasses):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(ZeroPadding2D((2, 2), input_shape=(nrows, ncols, nbands)))\n",
        "    model.add(Convolution2D(\n",
        "              filters=32,\n",
        "              kernel_size=(5, 5),\n",
        "              dilation_rate=(1, 1)))\n",
        "    model.add(BatchNormalization(axis=3))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(ZeroPadding2D((2, 2)))\n",
        "    model.add(MaxPooling2D(\n",
        "              pool_size=(5, 5),\n",
        "              strides=(1, 1)\n",
        "    ))\n",
        "    model.add(ZeroPadding2D((4, 4)))\n",
        "    model.add(Convolution2D(\n",
        "              filters=32,\n",
        "              kernel_size=(5, 5),\n",
        "              dilation_rate=(2, 2)\n",
        "    ))\n",
        "    model.add(BatchNormalization(axis=3))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(ZeroPadding2D((4, 4)))\n",
        "    model.add(MaxPooling2D(\n",
        "            pool_size=(9, 9),\n",
        "            strides=(1, 1)\n",
        "    ))\n",
        "    model.add(ZeroPadding2D((6, 6)))\n",
        "    model.add(Convolution2D(\n",
        "              filters=32,\n",
        "              kernel_size=(5, 5),\n",
        "              dilation_rate=(3, 3)\n",
        "    ))\n",
        "    model.add(BatchNormalization(axis=3))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(ZeroPadding2D((6, 6)))\n",
        "    model.add(MaxPooling2D(\n",
        "            pool_size=(13, 13),\n",
        "            strides=(1, 1)\n",
        "    ))\n",
        "    model.add(Convolution2D(\n",
        "              filters=nclasses,\n",
        "              kernel_size=(1, 1)\n",
        "    ))\n",
        "    model.add(keras.layers.Activation(\n",
        "              activation=\"softmax\"\n",
        "    ))\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=['accuracy'], optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "fcn = build_FCN(opt, PATCHSIZE, PATCHSIZE, NUMBER_BANDS,NUMBER_CLASSES)\n",
        "\n",
        "fcn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m]) #'adam'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9c7pcpCCKrm"
      },
      "source": [
        "fcn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZH40NdfvEi_"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHLXkT5zu4XR"
      },
      "source": [
        "def train(model, data, labels):\n",
        "    hist = model.fit(x=data,\n",
        "                     y=labels,\n",
        "                     epochs=NUMBER_EPOCHS,\n",
        "                     validation_split=0.20,\n",
        "                     verbose=2\n",
        "                    )\n",
        "    return hist\n",
        "\n",
        "history = train(fcn, Xtrain, Ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYzv5bETvf88"
      },
      "source": [
        "# Visualize the Training Output and Save the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjTlqWowvkQ6"
      },
      "source": [
        "Visualize Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzMLrbfLu4Uc"
      },
      "source": [
        "# plot learning curve\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(history.history[\"loss\"],label='Training Loss')\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(history.history[\"val_loss\"],label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14U_Qncb8Xy9"
      },
      "source": [
        "# plot error curve\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(1-np.array(history.history[\"acc\"]),label='Training Error')\n",
        "plt.title(\"Training and validation Error\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.plot(1-np.array(history.history[\"val_acc\"]),label='Validation Error')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9DGIt_vujh"
      },
      "source": [
        "Save output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttjxvNIJu4Ml"
      },
      "source": [
        "# save the trained network\n",
        "import imp, h5py\n",
        "imp.reload(h5py)\n",
        "model_fname = \"your file.hd5\"\n",
        "fcn.save(model_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxNHb1mwvynR"
      },
      "source": [
        "# Test the Accuracy of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrLW3jiKxCai"
      },
      "source": [
        "Xtest = image_list[\"00001\"]\n",
        "Ytest = label_list[\"00001\"]\n",
        "cut = 128\n",
        "overlap = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-G_JaVNxGtJ"
      },
      "source": [
        "def evaluate_predictions(Xtest,cut, overlap, Ytest):\n",
        "    \"\"\"\n",
        "    Function to predict full tiles strip-wise (as loading whole tiles might not fit in the memory).\n",
        "    \"\"\"\n",
        "    Ytest = Ytest.copy()\n",
        "    Ytest[Ytest!=2] = 0\n",
        "    Ytest[Ytest==2] = 1\n",
        "    ncols, nrows, nbands = Xtest.shape\n",
        "    Xtest = np.expand_dims(Xtest, axis=0)\n",
        "    total_map = np.zeros((nrows, ncols), dtype=np.uint8)\n",
        "    first = True\n",
        "    last = False\n",
        "    if nrows%cut==0:\n",
        "        numstrips = int(nrows/cut)\n",
        "    else:\n",
        "        numstrips = int(nrows/cut) + 1\n",
        "    for i in range(numstrips):\n",
        "        print(\"Strip number: %d\" % i)\n",
        "        if first:\n",
        "            striptop = 0\n",
        "            stripbottom = overlap\n",
        "            height = cut\n",
        "            X_sub = Xtest[:, cut*i-striptop:(cut*i)+height+stripbottom, :, :]\n",
        "            first = False\n",
        "        elif (not first) and (cut*(i+1)+1+overlap < nrows):\n",
        "            striptop = overlap\n",
        "            stripbottom = overlap\n",
        "            height = cut\n",
        "            X_sub = Xtest[:, cut*i-striptop:(cut*i)+height+stripbottom, :, :]\n",
        "        else:\n",
        "            print(\"Last hit!\")\n",
        "            striptop = overlap\n",
        "            stripbottom = 0\n",
        "            height = nrows - cut*i\n",
        "            if (striptop+height)%(4)!=0:\n",
        "                height = height*4\n",
        "            X_sub = Xtest[:, -(striptop+height):, :, :]\n",
        "            last = True        \n",
        "        sub_nrows = X_sub.shape[1]\n",
        "        sub_ncols = X_sub.shape[2]\n",
        "        model = fcn\n",
        "        \n",
        "        sub_ns, sub_nb, _, __ = X_sub.shape\n",
        "        cmap = model.predict_on_batch([X_sub])\n",
        "        cmap = np.argmax(cmap[0], axis=2)\n",
        "        if not last:\n",
        "            total_map[cut*i:cut*i+height, :] = cmap[striptop:striptop+height, 0:total_map.shape[1]]\n",
        "        else:\n",
        "            total_map[-(height):, :] = cmap[-(height):, 0:total_map.shape[1]]\n",
        "    return total_map\n",
        "predictions_FCN = evaluate_predictions(Xtest, cut, overlap, Ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39A-6oyt3qVo"
      },
      "source": [
        "import string\n",
        "from matplotlib import colors\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# set color codes of the classes\n",
        "_others = [221, 61, 14]\n",
        "_slums = [200, 199, 219]\n",
        "ccolors = (_slums, _others)\n",
        "NROWS, NCOLS, NBANDS = Xtest.shape\n",
        "\n",
        "\n",
        "def print_map(predictions, idxarray, filename=None, title=None, ccolors=None):\n",
        "    if predictions.size != idxarray.shape[0]:\n",
        "        raise ValueError(\"There should be the same number of \" +\n",
        "                         \"predictions and indices.\")\n",
        "    nrows, ncols = np.max(idxarray[:, 0])+1, np.max(idxarray[:, 1])+1\n",
        "    classifiedmap = np.zeros((nrows, ncols, 3), dtype=\"uint8\")\n",
        "    idx = 0\n",
        "    for prediction in predictions:\n",
        "        classifiedmap[idxarray[idx, 0],\n",
        "                      idxarray[idx, 1]] = np.asarray(ccolors[prediction])\n",
        "        idx += 1\n",
        "    if filename is None:\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(classifiedmap)\n",
        "        if title:\n",
        "            plt.suptitle(title)\n",
        "        plt.show()\n",
        "    else:\n",
        "        output_raster = gdal.GetDriverByName('GTiff').Create(filename,\n",
        "                                                             NCOLS,\n",
        "                                                             NROWS,\n",
        "                                                             NUMBER_CLASSES,\n",
        "                                                             gdal.GDT_Byte)\n",
        "        for i in range(NUMBER_CLASSES):\n",
        "            output_raster.GetRasterBand(i+1).WriteArray(classifiedmap.astype(np.uint8)[:, :, i])\n",
        "\n",
        "\n",
        "def get_confusion_matrix(predictions, labels):\n",
        "  \n",
        "    classes = np.unique(labels)\n",
        "    nbclasses = classes.size\n",
        "    if labels.size != predictions.size:\n",
        "        raise ValueError(\"There should be the same number of \" +\n",
        "                         \"predictions and labels.\")\n",
        "    merged = np.concatenate((predictions.reshape(predictions.size, 1),\n",
        "                             labels.reshape(labels.size, 1)), axis=1)\n",
        "    CM = np.zeros((classes[-1] + 1, classes[-1] + 1))\n",
        "    for c1 in classes:\n",
        "        for c2 in classes:\n",
        "            CM[c1, c2] = np.sum(np.logical_and(merged[:, 1] == c1,\n",
        "                                               merged[:, 0] == c2))\n",
        "    return CM\n",
        "\n",
        "\n",
        "def cartesian(arrays, out=None):\n",
        "    arrays = [np.asarray(x) for x in arrays]\n",
        "    dtype = arrays[0].dtype\n",
        "    n = np.prod([x.size for x in arrays])\n",
        "    if out is None:\n",
        "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
        "    m = int(n / arrays[0].size)\n",
        "    out[:, 0] = np.repeat(arrays[0], m)\n",
        "    if arrays[1:]:\n",
        "        cartesian(arrays[1:], out=out[0:m, 1:])\n",
        "        for j in range(1, arrays[0].size):\n",
        "            out[j*m:(j+1)*m, 1:] = out[0:m, 1:]\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-_wVMI0v32z"
      },
      "source": [
        "#plot Refrence Map\n",
        "f, axarr = plt.subplots(1,3)\n",
        "predictions = predictions_FCN\n",
        "norm_ccolors = np.array(ccolors)/255.0\n",
        "fig = axarr[0]\n",
        "cmap = colors.ListedColormap(norm_ccolors)\n",
        "bounds=[0,1,2]\n",
        "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "labels = Ytest[:, :, 0].copy()\n",
        "labels[labels!=2] = 0\n",
        "labels[labels==2] = 1\n",
        "fig.imshow(labels, cmap=cmap, norm=norm, interpolation=\"nearest\", origin=\"upper\")\n",
        "fig.set_title(\"Reference map\")\n",
        "\n",
        "ax= axarr[1]\n",
        "ax.imshow(predictions, cmap=cmap, norm=norm, interpolation=\"nearest\", origin=\"upper\")\n",
        "ax.set_title(\"Results FCN\")\n",
        "\n",
        "rectangles = [matplotlib.patches.Rectangle((0, 0), 1, 1, color=norm_ccolors[r]) for r in range(norm_ccolors.shape[0])]\n",
        "classes = [\"Non Burnt Area\", \" Burnt Area\"]\n",
        "#Create legend from custom artist/label lists\n",
        "fig.legend(rectangles, classes)\n",
        "labels = labels.astype(\"uint8\")\n",
        "\n",
        "data=Xtest\n",
        "data = data[:, :, 0:3]\n",
        "_ = data[:, :, 0].copy()\n",
        "data[:, :, 0] = data[:, :, 2]\n",
        "data[:, :, 2] = _\n",
        "data = data.astype(np.float)\n",
        "for i in range(data.shape[2]):\n",
        "    p2, p98 = np.percentile(data[:, :, i], (2, 98))\n",
        "    data[:, :, i] = exposure.rescale_intensity(data[:, :, i],in_range=(p2, p98))\n",
        "\n",
        "plt_sat=axarr[2]\n",
        "a=plt_sat.set_title(\"Satellite image\")\n",
        "_=plt_sat.imshow(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XyaqdrGwr08"
      },
      "source": [
        "CM = get_confusion_matrix(predictions, labels)\n",
        "OA = np.sum(np.diag(CM))/predictions.size\n",
        "PA_bldg = ((predictions[labels==0]==labels[labels==0]).sum())/(labels[labels==0].size)\n",
        "PA_rd = ((predictions[labels==1]==labels[labels==1]).sum())/(labels[labels==1].size)\n",
        "print(\"Accuracy metrics of FCN results\")\n",
        "print(\"Overall Accuracy: %f\" % OA)\n",
        "#print(\"F1_score: %f\" %(f1_score(labels, predictions, average=\"macro\")))\n",
        "print(\"PA of Burnt Area: %f\" % PA_bldg)\n",
        "print(\"PA of Not Burnt Area: %f\" % PA_rd)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}